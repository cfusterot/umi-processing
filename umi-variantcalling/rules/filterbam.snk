# rule mutation_bed:
#     input:
#         "table/{sample}.edit.csv"
#     output:
#         "filterbam/{sample}.bed"
#     params:
#         config['filter_bam']['padding']
#     resources:
#         time="00:30:00"
#     run:
#         dir_path = config["general"]["work_dir"] + "variantcalling"
#         conf = config['filter_bam']
#         print(f"{dir_path}/{input}")
#         anno_df = pd.read_csv(f"{dir_path}/{input}", sep='\t').sort_values(['Chr', 'Start']).iloc[:,:5]
#         if not len(anno_df.index):
#             anno_df.to_csv("filterbam/{sample}.bed", index=False, sep='\t', header=False)
#         else:
#             # get the bedfie with padded and collapsed regions
#             bed_df = anno_df.groupby('Chr').apply(reduce_regions, conf['padding'])
#             # remove Chr index
#             bed_df = bed_df.reset_index().drop(columns='level_1')
#             # write bed_df to file
#             print('MUTFILE', anno_df, '\n', 'BED', bed_df)
#             bed_df.to_csv(f"{dir_path}/{output}", index=False, sep='\t', header=False)
#             #print('MUTFILE', anno_df, '\n', 'BED', bed_df)
rule mutation_bed:
    input:
        "{}/table/{{sample}}.edit.csv".format(OUTDIR)
    output:
        "{}/filterbam/{{sample}}.bed".format(OUTDIR)
    params:
        config['filter_bam']['padding']
    resources:
        time="00:30:00"
    run:
        dir_path = config["general"]["work_dir"] + "variantcalling"
        conf = config['filter_bam']
        print(f"{input}")
        anno_df = pd.read_csv(f"{input}", sep='\t').sort_values(['Chr', 'Start']).iloc[:,:5]
        if not len(anno_df.index):
            anno_df.to_csv("filterbam/{sample}.bed", index=False, sep='\t', header=False)
        else:
            # get the bedfie with padded and collapsed regions
            bed_df = anno_df.groupby('Chr').apply(reduce_regions, conf['padding'])
            # remove Chr index
            bed_df = bed_df.reset_index().drop(columns='level_1')
            # write bed_df to file
            print('MUTFILE', anno_df, '\n', 'BED', bed_df)
            bed_df.to_csv(f"{output}", index=False, sep='\t', header=False)
            #print('MUTFILE', anno_df, '\n', 'BED', bed_df)

rule samtools_view:
    input:
        sample=lambda wildcards: input_bam[wildcards.sample]
    output:
        "{}/filterbam/{{sample}}.bam".format(OUTDIR),
    params:
        extra="-bhL ",
        bed="{}/filterbam/{{sample}}.bed".format(OUTDIR) # optional params string
    log:
        "{}/logs/samtools_view/{{sample}}.log".format(OUTDIR)
    resources:
        time="00:30:00",
        mem="60G",
        mem_mb="60G"
    shell:
        """
        samtools view {params.extra} {params.bed} {input.sample} -o {output} &> {log}
        """

rule samtools_index_vc:
    input:
        "{}/filterbam/{{sample}}.bam".format(OUTDIR)
    output:
        "{}/filterbam/{{sample}}.bai".format(OUTDIR)
    threads:
        4
    log:
        "{}/logs/samtools_index_vc/{{sample}}.log".format(OUTDIR)
    params:
        "" # optional params string
    resources:
        time="00:30:00"
    shell:
        """
        samtools index -b {input} {output} -@ {threads} &> {log}
        """
    

rule mpilup:
    input:
        # single or list of bam files
        bam=lambda wildcards: input_bam[wildcards.sample],
        reference_genome=config["reference"]["genome"]
    output:
        temp("{}/mpileup/{{sample}}.raw.pileup.gz".format(OUTDIR))
    log:
        "logs/samtools/mpileup/{sample}.log"
    params:
        extra="".join([" -q ", str(config['mpileup']['MAPQ']), " -Q ", str(config['mpileup']['Q'])]),  # optional
    resources:
        time="00:30:00"
    wrapper:
        "v3.1.0/bio/samtools/mpileup"


rule filter_pileup:
    input:
        "{}/mpileup/{{sample}}.raw.pileup.gz".format(OUTDIR)
    output:
        "{}/pileup/{{sample}}.pileup".format(OUTDIR)
    threads:
        2
    resources:
        time="00:30:00"
    params:
        ''.join([config["general"]['snakedir'],'/scripts/shell/cleanpileup.mawk'])
    shell:
        r"""
        mkdir -p pileup
        zcat {input} | {params} > {output}
        """


rule IGVnav:
    input:
        filter = "{}/table/{{sample}}.filter1.csv".format(OUTDIR),
        bam = "{}/filterbam/{{sample}}.bam".format(OUTDIR)
    output:
        IGVNav = "{}/filterbam/{{sample}}.filter1.txt".format(OUTDIR)
    threads:
        1
    resources:
        time="00:30:00"
    run:
        # selectinng the right filter2 file from the configs
        df = pd.read_csv(input.filter, sep='\t', index_col=False).iloc[:, :5]
        print(f'Loaded {input.filter}')
        for col in ['Call', 'Tags', 'Notes']:
            df[col] = ''
        df.loc[:, 'Chr'] = df['Chr'].str.replace('chr', '')
        df.to_csv(str(output), sep='\t', index=False)
        print(f"Written to {output.IGVNav}")
